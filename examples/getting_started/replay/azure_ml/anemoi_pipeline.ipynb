{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9458bf60",
   "metadata": {},
   "source": [
    "# Welcome to the ufs2arco + Anemoi + wxvx Framework in AzureML!\n",
    "\n",
    "This notebook will guide you through the basic steps of running the full framework.\n",
    "\n",
    "1) Create your training and validation datasets with ufs2arco\n",
    "2) Submit a training job with anemoi-training\n",
    "3) Run inference with anemoi-inference\n",
    "4) Run verification with wxvx\n",
    "\n",
    "More details will be provided in each individual section.\n",
    "\n",
    "## Step 0: Configure azure settings and permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7416b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment\n",
    "from azure.ai.ml import MLClient, Input, Output, command\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import Environment, BuildContext\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(),\n",
    "    ws.subscription_id,\n",
    "    ws.resource_group,\n",
    "    ws.name,\n",
    ")\n",
    "\n",
    "# Get your workspace's default datastore (or specify another registered datastore)\n",
    "default_ds = ml_client.datastores.get_default()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1fb6d50",
   "metadata": {},
   "source": [
    "## Step 1: Create conda environments\n",
    "You only need to do this once! Therefore, check if these environments were already created by someone else before running. After creation, you should be able to find them within the \"environments\" tab in AzureML. Anytime you re-run this, it will create a new version (e.g. myenv:1 would then become myenv:2). This is helpful if there is anything you wish to update in your environment (package versions, add an additional package, etc.)\n",
    "\n",
    "Environments we will create:\n",
    "1) ufs2arco for data processing\n",
    "2) anemoi for training a graph based model\n",
    "3) wxvx for post-processing and verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c14e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ufs2arco conda environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file=\"conf/conda/ufs2arco-conda.yaml\",\n",
    "    name=\"ufs2arco\",\n",
    "    description=\"ufs2arco environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9eb4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create anemoi conda environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-cuda11.8-cudnn8-ubuntu22.04\",\n",
    "    conda_file=\"conf/conda/anemoi-conda.yaml\",\n",
    "    name=\"anemoi\",\n",
    "    description=\"anemoi environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "\n",
    "ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cfc783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create wxvs conda environment\n",
    "\n",
    "env_docker_conda = Environment(\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04\",\n",
    "    conda_file=\"conf/conda/wxvx_conda.yaml\",\n",
    "    name=\"wxvx\",\n",
    "    description=\"wxvx environment created from a Docker image plus Conda environment.\",\n",
    ")\n",
    "\n",
    "returned_job = ml_client.environments.create_or_update(env_docker_conda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dd6d7c",
   "metadata": {},
   "source": [
    "## Step 2: Create replay dataset with ufs2arco\n",
    "Saves a dataset to your default datastore that will include training and validation data together in one dataset. The zarr is saved to your default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a89f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"replay/data\"\n",
    "output_zarr = \"replay.zarr\"\n",
    "outputs = Output(\n",
    "    type=\"uri_folder\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/{output_path}/{output_zarr}\" \n",
    ")\n",
    "\n",
    "command_job = command(\n",
    "    code=\"./data\",\n",
    "    command=f\"bash submit_ufs2arco.sh ${{outputs.output_blob}} {output_path} {output_zarr}\",\n",
    "    environment=\"ufs2arco:2\",\n",
    "    compute=\"Standard-D13-v2\",\n",
    "    experiment_name=\"ufs2arco\",\n",
    "    display_name=\"training_dataset\",\n",
    "    outputs={\"output_blob\": outputs},\n",
    ")\n",
    "\n",
    "returned_job = ml_client.jobs.create_or_update(command_job)\n",
    "\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e07b38",
   "metadata": {},
   "source": [
    "## Step 3: Submit a training job with anemoi-core\n",
    "\n",
    "Checkpoints and plots all saved to the default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6dc2728",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"replay/data\"\n",
    "input_zarr = \"replay.zarr\"\n",
    "replay_inputs = Input(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"ro_mount\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/{input_path}/{input_zarr}\",\n",
    ")\n",
    "\n",
    "outputs = Output(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"upload\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/training_output/\",\n",
    ")\n",
    "\n",
    "command_job = command(\n",
    "    code=\"./training\",\n",
    "    command=f\"bash submit_training.sh ${{inputs.data}} ${{outputs.output_dir}}\",\n",
    "    environment=\"anemoi:7\",\n",
    "    compute=\"Standard-NC4as-T4-v3\",\n",
    "    experiment_name=\"anemoi-training\",\n",
    "    display_name=\"anemoi-training\",\n",
    "    outputs={\"output_dir\": outputs},\n",
    "    inputs={\"data\": replay_inputs},\n",
    ")\n",
    "\n",
    "returned_job = ml_client.jobs.create_or_update(command_job)\n",
    "\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88621a",
   "metadata": {},
   "source": [
    "## Step 4: Submit inference job with anemoi-inference\n",
    "\n",
    "Load the model checkpoint from the default datastore and create one 240-hr forecast. The output is saved to the default datastore. We currently use a python script to submit inference instead of simply using \"anemoi-inference run\" command because it makes it a tiny bit easier to load everything. We can still use the other way, but I found this to be a little easier.\n",
    "\n",
    "- TODO: create options for this step, and build out this python script to be a lot more robust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3924473d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"replay/training-output/checkpoint/3f476fd7-65ca-4d98-b3d5-b622d88a0d7d\"\n",
    "input_ckpt = \"inference-last.ckpt\"\n",
    "ckpt_input = Input(\n",
    "    type=\"uri_file\",\n",
    "    mode=\"ro_mount\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/{input_path}/{input_ckpt}\",\n",
    ")\n",
    "\n",
    "input_path = \"replay/data\"\n",
    "zarr_input = Input(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"ro_mount\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/{input_path}\",\n",
    ")\n",
    "\n",
    "outputs = Output(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"upload\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/replay/inference\",\n",
    ")\n",
    "\n",
    "command_job = command(\n",
    "    code=\"./inference\",\n",
    "    command=f\"python inference.py ${{inputs.ckpt}} ${{inputs.zarr}} ${{outputs.output_dir}}\",\n",
    "    environment=\"anemoi:7\",\n",
    "    compute=\"Standard-NC4as-T4-v3\",\n",
    "    experiment_name=\"anemoi-inference\",\n",
    "    display_name=\"anemoi-inference\",\n",
    "    outputs={\"output_dir\": outputs},\n",
    "    inputs={\n",
    "        \"ckpt\": ckpt_input,\n",
    "        \"zarr\": zarr_input,\n",
    "    },\n",
    ")\n",
    "\n",
    "returned_job = ml_client.jobs.create_or_update(command_job)\n",
    "\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a854cbfd",
   "metadata": {},
   "source": [
    "## Step 5: Submit verification job with wxvx\n",
    "\n",
    "Load inference, post-process the output so that will work with wxvx, and run verification against the GGFS for a handful of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f55c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"replay/inference\"\n",
    "zarr_input = Input(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"ro_mount\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/{input_path}\",\n",
    ")\n",
    "\n",
    "outputs = Output(\n",
    "    type=\"uri_folder\",\n",
    "    mode=\"upload\",\n",
    "    path=f\"azureml://datastores/{default_ds.name}/paths/replay/verification\",\n",
    ")\n",
    "\n",
    "command_job = command(\n",
    "    code=\"./verification\",\n",
    "    command=f\"bash submit_wxvx.sh ${{inputs.zarr}} ${{outputs.output_dir}}\",\n",
    "    environment=\"wxvx:4\",\n",
    "    compute=\"Standard-D13-v2\",\n",
    "    experiment_name=\"wxvx\",\n",
    "    display_name=\"wxvx\",\n",
    "    outputs={\"output_dir\": outputs},\n",
    "    inputs={\"zarr\": zarr_input},\n",
    ")\n",
    "\n",
    "returned_job = ml_client.jobs.create_or_update(command_job)\n",
    "\n",
    "returned_job.services[\"Studio\"].endpoint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
