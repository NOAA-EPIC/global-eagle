defaults:
  - data: zarr
  - dataloader: native_grid
  - diagnostics: evaluation
  - datamodule: single
  - hardware: example
  - graph: multi_scale
  - model: graphtransformer
  - training: default
  - _self_

# set to true to switch on config validation
config_validation: True

data:
  forcing:
    - cos_latitude
    - sin_latitude
    - cos_longitude
    - sin_longitude
    - cos_julian_day
    - sin_julian_day
    - cos_local_time
    - sin_local_time
    - insolation
    - land_static
    - hgtsfc_static
  normalizer:
    default: mean-std
    std:
      - spfh2m
      - spfh_25
      - spfh_75
      - spfh_125
      - spfh_175
      - spfh_225
      - spfh_275
      - spfh_325
      - spfh_375
      - spfh_425
      - spfh_475
      - spfh_525
      - spfh_575
      - spfh_625
      - spfh_675
      - spfh_725
      - spfh_775
      - spfh_825
      - spfh_875
      - spfh_925
      - spfh_975
    max:
      - hgtsfc_static
    none:
      - cos_latitude
      - sin_latitude
      - cos_longitude
      - sin_longitude
      - cos_julian_day
      - sin_julian_day
      - cos_local_time
      - sin_local_time
      - insolation
      - land_static

dataloader:
  dataset: ${hardware.paths.data}/replay.zarr
  num_workers:
    training: 2
    validation: 2
    test: 2
  batch_size:
    # note that the batch_size is set locally, so
    # global_batch_size = num_nodes * num_gpus_per_node * batch_size / num_gpus_per_model
    training: 1
    validation: 1
    test: 1
  training:
    start: "2022-01-01"
    end: "2022-01-02"
  validation:
    start: "2022-01-03"
    end: "2022-01-04"
  test:
    start: "2022-01-05"
    end: "2022-01-06"

diagnostics:
  plot:
    frequency:
      batch: 5_000
      epoch: 1

    parameters:
      - tmp_825
      - ugrd_825
      - vgrd_825
      - tmp2m
      - ugrd10m
      - vgrd10m
      - pressfc

    callbacks:
      # Add plot callbacks here
      - _target_: anemoi.training.diagnostics.callbacks.plot.GraphTrainableFeaturesPlot
        every_n_epochs: 5
      - _target_: anemoi.training.diagnostics.callbacks.plot.PlotLoss
        # group parameters by categories when visualizing contributions to the loss
        # one-parameter groups are possible to highlight individual parameters
        parameter_groups:
          moisture: []
          sfc_wind: [ugrd10m, vgrd10m]
        every_n_batches: ${diagnostics.plot.frequency.batch}
      - _target_: anemoi.training.diagnostics.callbacks.plot.PlotSample
        sample_idx: ${diagnostics.plot.sample_idx}
        per_sample: 6
        parameters: ${diagnostics.plot.parameters}
        every_n_batches: ${diagnostics.plot.frequency.batch}
        #Defining the accumulation levels for precipitation related fields and the colormap
        accumulation_levels_plot: [
            0,
            0.05,
            0.1,
            0.25,
            0.5,
            1,
            1.5,
            2,
            3,
            4,
            5,
            6,
            7,
            100,
          ] # in mm
        precip_and_related_fields: ${diagnostics.plot.precip_and_related_fields}
        colormaps: ${diagnostics.plot.colormaps}
      - _target_: anemoi.training.diagnostics.callbacks.plot.PlotSpectrum
        # every_n_batches: 100 # Override for batch frequency
        # min_delta: 0.01 # Minimum distance between two consecutive points
        sample_idx: ${diagnostics.plot.sample_idx}
        every_n_batches: ${diagnostics.plot.frequency.batch}
        parameters:
          - tmp_825
          - tmp2m
          - ugrd10m
          - vgrd10m
      - _target_: anemoi.training.diagnostics.callbacks.plot.PlotHistogram
        sample_idx: ${diagnostics.plot.sample_idx}
        every_n_batches: ${diagnostics.plot.frequency.batch}
        precip_and_related_fields: ${diagnostics.plot.precip_and_related_fields}
        parameters:
          - tmp_825
          - tmp2m
          - ugrd10m
          - vgrd10m

hardware:
  num_gpus_per_model: 1
  paths:
    output: training-output/
    data: ../data
    graph: ../data
  files:
    dataset: replay.zarr

model:
  # turn these down for a hello world setup
  num_channels: 128
  processor:
    num_layers: 8
  bounding:
    - _target_: anemoi.models.layers.bounding.ReluBounding #[0, infinity)
      variables:
        - spfh2m
        - spfh_25
        - spfh_75
        - spfh_125
        - spfh_175
        - spfh_225
        - spfh_275
        - spfh_325
        - spfh_375
        - spfh_425
        - spfh_475
        - spfh_525
        - spfh_575
        - spfh_625
        - spfh_675
        - spfh_725
        - spfh_775
        - spfh_825
        - spfh_875
        - spfh_925
        - spfh_975

training:
  max_steps: 50
  lr:
    warmup: 10 # number of warmup iterations
    rate: 0.625e-4 #local_lr
    iterations: ${training.max_steps} # NOTE: When max_epochs < max_steps, scheduler will run for max_steps
    min: 3e-7 #Not scaled by #GPU
